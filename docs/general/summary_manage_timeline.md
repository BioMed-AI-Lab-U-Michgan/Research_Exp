## 如何管理大规模实验和多个进程

随着时代进步，我们可用的 GPU 也逐渐增多了。从很早之前的合用 2080，到我本科的时候的人均一张 3090 再到现在使用 cluster 跑大规模实验。在我们有机会同时管理调度多个实验进程的同时，如何管理这些进程也成为了一个挑战。由于每个实验占用的时间并不相同，导致我们有大量的，介于不同的实验完成前后之间的零碎时间。如果这些时间拿去摸鱼，无疑会降低我们的工作效率。相反，我们需要利用这些时间。在本日记中，我希望总结我最近几个项目的实验经验，希望帮助自己也帮助大家提高科研工作中各个事务的并行化程度，减少因为等结果而摸鱼的时间。当然，这样会活得很心累，但是有时候 ddl 很紧的话，还是得玩玩命的。

### 分清主次和优先级

我们其实可以借鉴操作系统课程中学到的知识，去调度我们的各个实验进程。这里我们的核心目标是，**尽量让 A 实验不要等 B 实验，尽量让 GPU 不要空转，同时最快出所有实验结果**。

对于每个实验，我们首先需要确定：这个实验占用的时间和计算资源开销是多少？做这个实验我需要话多少时间改 evaluation 或者模型结构的代码？我还剩多少计算资源可以调用？这个实验的结果会影响后续哪些事务的安排和规划？xx 实验出现了 xx 结果才有必要这个实验？通常我们可以根据这些因素来确定实验占用资源的数据，以及他们的优先级，从而确定什么时候需要安排做什么实验。

根据上面的因素，我们可以将需要做的实验按照不同分类标准分为如下的几个类型：

按照实验性质：

1. 带了预期目标的探索，希望找到有趣的结论来给一些 insight 或者 support claim
2. 在做 main table 的时候跑 baseline
3. 探索自己的方法应该怎么做才能 work
4. 设若干组超参数跑自己的方法
5.  跑消融实验和分析实验

这里我总结最近的经验认为应该是 1>2>3>4=5 的。1>2 这是因为：在我们确定感兴趣的 topic 并且读了很多文章之后，我们往往会有一些关于现有方法的不足的猜想，或者对于这个任务的挑战所在之处的猜想。先确定问题所在的地方，往往更科学，后面工作推进更顺利。2>3 是因为，跑 baseline 的时候我们不仅把表格做出来了，我们也能确定什么 technique 是真的 work，我们可以抄哪些 trick。往往对于简单（能即插即用）且引用高 （说明有效，且不强）的方法，我会移植到自己的 codebase 来跑，这样如果想加进来，会变得很方便。4=5是因为，其实我们也不确定有几个不太重要的 technique 是不是真的有效，索性并在一起，考虑 technique $\times$ hyper-params，跑几十组看看哪个更好，选最适合故事线、消融结果最符合 claim 和直觉的实现。

按照实验类型：

1. pre-training. 我们把自然领域到垂类的 adapt 例如：自然图像 pre-trained backbone->医学图像归为这一类. 对于 stable diffusion， 从自然图像到 X-Ray image domain，大概是 64张A100 半天~一天 [1]。或者 medical pre-train vision-language model 的话，大概 8xA100 跑一天。
2. fine-tuning. 我们可以把 foundation model train好之后的 downstream fine-tuning 归类为这个。一般是单卡 3090~A100, 两小时以内。
3. evaluation. 如果是生成的话，一个 number 至少是要在 500 左右的 sample 上测出来的。例如用 stable diffusion 生成的话，用单卡 A100 & ddim step=20，大概半小时内能出一组。CLIP-based zero-shot 应该也不会耗费太多时间，大概是分类任务的若干倍。如果是监督任务，例如分类、分割、识别，几乎不耗时间。

接下来我们举两个例子。

对于整个工作的实验布局：如果我们目前有一条比较有信心的潜在的故事线：A 挑战影响过去的方法 $E_{1\sim N}$ 在 B 任务上的表现，这是通过 C 问题造成的，我们的方法 D 通过解决问题 C， 克服了 B 任务上的 A 挑战。那么我们首先确定一个 naive 的baseline $E_1$ 然后在问题 A 的场景下针对 C 问题跑全面的探究实验，然后同时实现其他 baseline $E_{2\sim N}$ 和 naive 的我们的方法 $D_0$. 在收集完结果并且充分分析后，我们先把 $D_0$ 交上去，然后再跑的时候准备一轮迭代，这轮迭代最好是控制大部分 technique component 不变，仅仅改变某个 component F的选取的。$D_0$ 跑完之后我们往往会得到一些结论，然后把关于 F 的迭代实验交上去，分析 $D_0$ 的结果之后，再考虑哪些地方可以优化，写下一轮迭代优化的代码。这样我们可以通过若干轮迭代，知道在我们的方法设计下，我们是否能达到至少和 SOTA comparable 的情况，哪些 implementation/trick 能让我们的效果最好。再基本确定之后，我们就可以设若X组随机数和Y组超参数，跑XY轮实验，找到最好的结果。如上的中间结果其实都可以作为消融实验或者分析实验的一部分，这样自底向上的打法会比先刷点再做消融更好一些。

在具体操作上，例如我们在做 pre-training task。我们可以在每天睡之前，把这一轮迭代的 pre-training 交上去，第二天起来应该还没有跑完，这个时候我们先测之前 pre-train 好的 backbone，然后再设计下一步的计划。通常情况，这里是 downstream fine-tune task，因此一次需要1小时左右，在这个期间我们可以开一个新的gpu，在上面写新的 evaluation  code或者写新的dataset 的loader，或者写写文章的不太重要的部分。

### 多项目流水线行进

我们可以注意到，如果手里只有一个项目的话，在实验部分，我们只能尽量让 BCD 步骤少花费时间等待 A 步骤完成。中间等待的时间我们应该做什么呢？ 我们联想到计算机组成的知识，为什么不像cpu一样流水线作业呢？接下来我们先回顾一下典型的科研流程。

备注：这里假设我们都是一个人负责大部分工作的独立工作模式，这里的流水线指的是个人层面的多项目流水线作业，而非大兵团流水线作战。

首先我们会听 seminar 和闭门会，参加线上线下的讲座（混点 cookie 吃），这个阶段我们称为idea随机生成器阶段。随后我们会知道目前大家关注什么问题，结合自己感兴趣的点之后我们会有一个初步方向，但是还不确定什么能做，因此我们会进行调研，这个阶段我们称为发掘潜力项目阶段。随后我们会做实验验证/empirical study 我们的想打的点是否能做，这个是验证阶段。第四阶段是做方法和跑大规模实验，通常也会比较耗时间。第五阶段也是写作阶段（当然写作有部分是可以早于实验结果收集完成的，但是好的文章往往修改5遍以上，修改的耗时往往不低于一周）。

那么在这个情况下，我们的流水线可以是：在项目1的方法上改代码和debug，在后台跑着项目2的大规模验证性实验；在项目 1 等现象的时候，我们做项目3的工作的调研，没事的时候去 seminar 混点下午茶。而写作的话，比较消耗脑力，而且需要较长的整块时间，应该仅次于推理论，这个我往往和做方法归为一个阶段来处理，等到后台实验不太需要我每15分钟就 check 一次的时候来写。

### 其他的利用时间的 tips

读研读博对于准备混学术圈的uu来说，是一场一直到45岁都没法躺平的长跑，多出去和人 social，保持良好的作息，锻炼身体，以及其他的方式放松自己都是非常重要的。**假设我们都是卷逼**，为了提高时间利用率，同时劳逸结合，我的习惯是和方向相近的人一起出去玩。以下是一些例子：

1. 我和 labmate 都喜欢运动，他们健身的时候会叫上我一起。我们休息的时候会趁着大脑活跃讨论一些好的问题解决方案或者 idea。而且一起流汗流血更能培养感情，加深信任。（在运动队呆过的朋友应该对这个体会比较深）
2. 医学院和计算机学院的老师学长学姐很注重锻炼身体，他们喜欢一些有氧运动，羽毛球网球之类的，正好我从小比较擅长，我就会去出现在球场和他们混熟，有时候可以交流一些经验，了解同行在做什么，甚至在关键的时候能帮上忙。
3. 平时如果无聊想聊天，可以多加一些同行群，例如AI/ML phd申请群，找工群，教职互助群，这里面也常常能得到一些有用的信息。
4. 吃饭的时候我会通过一些干货多的案例类的长视频，来复习一下商业和金融，这里面 insight 往往也能很好的帮助我们思考如何选择并投资最有价值的课题和方向。

[1] Chambon P, Bluethgen C, Delbrouck J B, et al. Roentgen: Vision-language foundation model for chest x-ray generation[J]. arXiv preprint arXiv:2211.12737, 2022.
